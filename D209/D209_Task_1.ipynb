{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMwFIiE1D31P3Vuu1a4JVk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nestrada79/MSDA/blob/main/D209/D209_Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX7XyI2CtM8Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Part I: Research Question"
      ],
      "metadata": {
        "id": "QUbNq0u-tcsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.  Describe the purpose of this data mining report by doing the following:\n"
      ],
      "metadata": {
        "id": "6O0wEE8Wtfas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.  Propose one question relevant to a real-world organizational situation that you will answer using one of the following classification methods:\n",
        "\n",
        "- k-nearest neighbor (KNN)\n",
        "\n",
        "- Naive Bayes"
      ],
      "metadata": {
        "id": "hQzVhErRuHUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> What factors are most predictive of a patient being readmitted to the hospital within a month after their initial discharge?"
      ],
      "metadata": {
        "id": "2oC2xK8DmeKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.  Define one goal of the data analysis. Ensure that your goal is reasonable within the scope of the scenario and is represented in the available data.\n"
      ],
      "metadata": {
        "id": "GVBf64f2tUks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To develop a predictive model to identify key factors influencing hospital readmission within one month of discharge.\n",
        "\n",
        "- To identify and quantify the influence of various factors, such as medical history, demographic details, and hospital services received, on the risk of readmission."
      ],
      "metadata": {
        "id": "9HwxbLeOzk-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " # Part II: Method Justification"
      ],
      "metadata": {
        "id": "kKz4dDA4tbo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.  Explain the reasons for your chosen classification method from part A1 by doing the following:\n",
        "\n"
      ],
      "metadata": {
        "id": "z_O1G4AltUru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.  Explain how the classification method you chose analyzes the selected data set. Include expected outcomes."
      ],
      "metadata": {
        "id": "7HXZ9z3YtUvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbors (KNN) is a classification method well-suited for this dataset, which includes various patient health and demographic variables.\n",
        "\n",
        "1. **Functionality:**\n",
        "   - KNN works by finding the 'k' closest data points (neighbors) to a new data point based on similarity in features. In our dataset, this means identifying the most similar patients in terms of demographics, medical conditions, and hospital stay characteristics.\n",
        "\n",
        "2. **Classification Decision:**\n",
        "   - The algorithm assigns the new data point to the most common class among its 'k' nearest neighbors. For predicting hospital readmissions, it looks at the 'ReAdmis' status of the nearest neighbors and predicts whether a new patient will be readmitted based on these.\n",
        "\n",
        "3. **Expected Outcomes:**\n",
        "   - The model's effectiveness will largely depend on features like age, medical history, and length of hospital stay. I anticipate that the KNN model will be able to highlight key factors that correlate with higher readmission rates.\n",
        "\n",
        "4. **Evaluation:**\n",
        "   - The performance of the KNN model on our dataset will be evaluated using accuracy and AUC metrics, providing insight into its reliability for this specific application.\n",
        "\n",
        "In this context, KNN's ability to capture the nuanced relationships in multi-feature medical data makes it a promising tool for identifying patterns leading to hospital readmissions.\n",
        "\n"
      ],
      "metadata": {
        "id": "hP0WLKqFztD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.  Summarize one assumption of the chosen classification method."
      ],
      "metadata": {
        "id": "37avWmhGtUyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A key assumption of the K-Nearest Neighbors (KNN) algorithm is that similar things exist in close proximity. In other words, KNN assumes that data points that are near each other are likely to be in the same category."
      ],
      "metadata": {
        "id": "XFTnPob60Lbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.  List the packages or libraries you have chosen for Python or R, and justify how each item on the list supports the analysis."
      ],
      "metadata": {
        "id": "XSVLCI4SxzED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python Libraries:\n",
        "\n",
        "- pandas: For data handling and manipulation.\n",
        "- numpy: For numerical operations.\n",
        "- scikit-learn: For implementing KNN and preprocessing data.\n",
        "- matplotlib, seaborn: For visualizing data."
      ],
      "metadata": {
        "id": "D-QUW3zJ0UYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III: Data Preparation"
      ],
      "metadata": {
        "id": "9ttwZ43Ax3Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C.  Perform data preparation for the chosen data set by doing the following:"
      ],
      "metadata": {
        "id": "O5GWAY7Hx7Nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.  Describe one data preprocessing goal relevant to the classification method from part A1.\n"
      ],
      "metadata": {
        "id": "TdIgtqv9x9mX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.  Identify the initial data set variables that you will use to perform the analysis for the classification question from part A1, and classify each variable as continuous or categorical.\n"
      ],
      "metadata": {
        "id": "tKy1ekpeyAFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.  Explain each of the steps used to prepare the data for the analysis. Identify the code segment for each step.\n"
      ],
      "metadata": {
        "id": "4XoJMzYqyAIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import statements\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import warnings\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "\n",
        "# Set the display option to show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Suppress all warning\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Bb2aowVQkTSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Describe your data cleaning goals and the steps used to clean the data to achieve the goals that align with your research question including the annotated code.\n",
        "\n",
        "**Goals:**\n",
        "\n",
        "**Identify and Handle Missing Values:** Ensure that the dataset does not have any gaps or missing data that could compromise the analysis.\n",
        "\n",
        "**Check for Duplicates:** Ensure there's no redundancy in the data. Remove any duplicate rows if found.\n",
        "\n",
        "**Ensure Appropriate Data Types:** Confirm that each column's data type aligns with the nature of the data it contains.\n",
        "\n",
        "**Remove Irrelevant Columns:** Eliminate columns that don't contribute value to the research question to make the dataset and subsequent analysis more focused."
      ],
      "metadata": {
        "id": "bWDUF3eEkXpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset into pandas dataframe\n",
        "#Reloading dataframe at this point to make the cleaning process easier to roll back without having to rerun any previous analysis\n",
        "medical_data = pd.read_csv('/content/medical_clean.csv')"
      ],
      "metadata": {
        "id": "Mn7u9ZLAkTa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visually inspecting the first 10 rows\n",
        "medical_data.head(10)"
      ],
      "metadata": {
        "id": "5oSNvri1kTh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_data.info()"
      ],
      "metadata": {
        "id": "QNbHqa03kTmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Cleaning Steps"
      ],
      "metadata": {
        "id": "XIAffepHkrvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check for missing values\n",
        "missing_values = medical_data.isnull().sum()\n",
        "missing_values"
      ],
      "metadata": {
        "id": "XDYNdKyhknMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Check for duplicates\n",
        "duplicate_rows = medical_data.duplicated().sum()\n",
        "duplicate_rows"
      ],
      "metadata": {
        "id": "eD_0h2a4knRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Check data types of columns\n",
        "data_types = medical_data.dtypes\n",
        "data_types"
      ],
      "metadata": {
        "id": "xs45Br7uknUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Findings**\n",
        "- There are no missing values in the dataset.\n",
        "- There are no duplicate rows in the dataset.\n",
        "- The data types seem appropriate for each column, with a mix of numerical (int64 and float64) and categorical (object) data types.<P>\n",
        "\n",
        "There are a few columns that are not relevant to the research question so they will need to be dropped. These include **CaseOrder, Customer_id, Interaction, UID, City, State, County, Zip, Lat, Lng, TimeZone**\n",
        "\n",
        "I am also removing the **Complication_risk** column from my analysis as it does not make sense to include a risk calculation within my analysis to identify readmission risk especially without knowing *how* this calculation was made, with which factors and at what point in a patient's stay this calculation was made. A high complication risk assessed at the time of admission would have different meaning from a high complication risk assessed at the time of discharge. I am using my domain knowledge as a nurse to make this decision.\n",
        "\n",
        "**Item1,\tItem2,\tItem3, Item4,\tItem5,\tItem6,\tItem7** and\t**Item8** will also be removed because they are not needed. These are survey items that related to patient satisfaction and logically do not have the ability to affect whether a patient gets readmitted or. While there might be some correlation between patient satisfaction scores and whether a patient is at risk of being readmitted including these scores may skew the analysis. If I was asking a research question like do patients who receive better service as measured by customer satisfaction survey have better outcomes with few readmissions then it might make sense to leave them in. But this is outside the scope of my research question.\n",
        "\n",
        "Instinctively I want to remove **Job** from my analysis for similar reasons but I suspect there might be some relationship between a patient's job and their access to preventative medical which may reduce readmissions so I am leaving it in at this stage.\n"
      ],
      "metadata": {
        "id": "A1-8Li4Xk2bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to be dropped from the dataset\n",
        "columns_to_drop = [\n",
        "    'CaseOrder', 'Customer_id', 'Interaction', 'UID', 'City', 'State', 'County', 'Zip', 'Lat', 'Lng', 'TimeZone', 'Complication_risk',\n",
        "    'Item1', 'Item2', 'Item3', 'Item4', 'Item5', 'Item6', 'Item7', 'Item8'\n",
        "]\n",
        "\n",
        "# Dropping the irrelevant columns\n",
        "medical_data_cleaned = medical_data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Display the shape of the dataset after dropping the columns\n",
        "medical_data_cleaned.shape"
      ],
      "metadata": {
        "id": "q22KEEESkzHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the original numerical variables\n",
        "original_numerical_vars = ['Population', 'Children', 'Age', 'Income', 'VitD_levels', 'Doc_visits',\n",
        "                           'Full_meals_eaten', 'vitD_supp', 'Initial_days', 'TotalCharge', 'Additional_charges']\n",
        "\n",
        "# One-hot encoding the categorical variables\n",
        "categorical_data = medical_data_cleaned.drop(original_numerical_vars, axis=1)\n",
        "medical_data_encoded = pd.get_dummies(categorical_data, drop_first=True)\n",
        "\n",
        "# Initialize the standard scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scale the numerical variables\n",
        "scaled_numerical_data = scaler.fit_transform(medical_data_cleaned[original_numerical_vars])\n",
        "\n",
        "# Convert the scaled numerical data back to a DataFrame\n",
        "scaled_numerical_df = pd.DataFrame(scaled_numerical_data, columns=original_numerical_vars)\n",
        "\n",
        "# Concatenate scaled numerical variables with one-hot encoded variables\n",
        "medical_transformed = pd.concat([scaled_numerical_df, medical_data_encoded], axis=1)\n",
        "\n",
        "# Display the first few rows of the final dataset\n",
        "medical_transformed.head()"
      ],
      "metadata": {
        "id": "soawyLqJlJ_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_vif(data):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = data.columns\n",
        "\n",
        "    # Calculating VIF for each feature\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(len(data.columns))]\n",
        "\n",
        "    return vif_data\n",
        "\n",
        "features = medical_transformed.drop('ReAdmis_Yes', axis=1)\n",
        "vif_data = calculate_vif(features)\n",
        "\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "LK0eynw6lS7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with high VIF\n",
        "high_vif_columns = ['Initial_days', 'TotalCharge', 'Additional_charges']\n",
        "medical_logistic_prepared = medical_transformed.drop(high_vif_columns, axis=1)"
      ],
      "metadata": {
        "id": "NN6RV1oylXwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n8ZP5rhXlYK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wVqFzD-BlYPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.  Provide a copy of the cleaned data set.\n"
      ],
      "metadata": {
        "id": "QsybRwBHyATr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame as a CSV file\n",
        "medical_logistic_prepared.to_csv('medical_logistic_prepared.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "RhjlJLpwlapI",
        "outputId": "3c42c80d-0f2e-446b-c1d8-69e2cab32f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e71dcc2c2f64>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the DataFrame as a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmedical_logistic_prepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'medical_logistic_prepared.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'medical_logistic_prepared' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part IV: Analysis"
      ],
      "metadata": {
        "id": "47AA9e3pyR5E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFMm5W_ByRXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D.  Perform the data analysis and report on the results by doing the following:"
      ],
      "metadata": {
        "id": "o5RLy7w1yXyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.  Split the data into training and test data sets and provide the file(s).\n"
      ],
      "metadata": {
        "id": "u5FXtI-DybmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Describe the analysis technique you used to appropriately analyze the data. Include screenshots of the intermediate calculations you performed."
      ],
      "metadata": {
        "id": "R47zkq_lybqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Describe the analysis technique you used to appropriately analyze the data. Include screenshots of the intermediate calculations you performed."
      ],
      "metadata": {
        "id": "L5Z8YZAkynkf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJ4-lpvdynEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part V: Data Summary and Implications"
      ],
      "metadata": {
        "id": "IDbMikSFybt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E.  Summarize your data analysis by doing the following:"
      ],
      "metadata": {
        "id": "pAMnXrXbyuxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.  Explain the accuracy and the area under the curve (AUC) of your classification model."
      ],
      "metadata": {
        "id": "PDfcVwVJyusW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.  Discuss the results and implications of your classification analysis."
      ],
      "metadata": {
        "id": "-2Q5uRsRyuoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.  Discuss one limitation of your data analysis."
      ],
      "metadata": {
        "id": "aXvxDmLayz4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.  Recommend a course of action for the real-world organizational situation from part A1 based on your results and implications discussed in part E2."
      ],
      "metadata": {
        "id": "JN6OLxQ_y0DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FpVGiXzDy0Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2TxUNxmytZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}